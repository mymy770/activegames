# BACKUP AUTOMATIQUE ACTIVELASER

## üéØ SOLUTION 1: Script Local (Simple)

### Cr√©er un script de backup automatique

**Fichier: `scripts/backup-supabase.sh`**

```bash
#!/bin/bash

# Configuration
PROJECT_ID="zapwlcrjnabrfhoxfgqo"
BACKUP_DIR="/path/to/your/NAS/backups/supabase"
DATE=$(date +%Y%m%d_%H%M%S)

# Cr√©er le dossier de backup
mkdir -p $BACKUP_DIR

# Export SQL via Supabase CLI
supabase db dump --project-id $PROJECT_ID > $BACKUP_DIR/backup_$DATE.sql

# Garder seulement les 30 derniers backups
ls -t $BACKUP_DIR/backup_*.sql | tail -n +31 | xargs rm -f

echo "‚úÖ Backup cr√©√©: $BACKUP_DIR/backup_$DATE.sql"
```

### Automatiser avec Cron (Mac)

```bash
# Ouvrir le crontab
crontab -e

# Ajouter une ligne pour backup toutes les heures
0 * * * * /Users/jeremy/Desktop/claude/activelaser/scripts/backup-supabase.sh

# OU toutes les 6 heures
0 */6 * * * /Users/jeremy/Desktop/claude/activelaser/scripts/backup-supabase.sh

# OU tous les jours √† 3h du matin
0 3 * * * /Users/jeremy/Desktop/claude/activelaser/scripts/backup-supabase.sh
```

---

## üöÄ SOLUTION 2: API Supabase Management (Plus avanc√©)

### Script Node.js pour backup automatique

**Fichier: `scripts/backup-api.js`**

```javascript
// Installation: npm install @supabase/supabase-js node-fetch

const fs = require('fs');
const path = require('path');

// Configuration
const SUPABASE_ACCESS_TOKEN = "ton-token-ici"; // √Ä g√©n√©rer sur https://supabase.com/dashboard/account/tokens
const PROJECT_REF = "zapwlcrjnabrfhoxfgqo";
const BACKUP_DIR = "/path/to/your/NAS/backups/supabase";

async function createBackup() {
  try {
    // 1. Lister les backups disponibles
    const response = await fetch(
      `https://api.supabase.com/v1/projects/${PROJECT_REF}/database/backups`,
      {
        headers: {
          'Authorization': `Bearer ${SUPABASE_ACCESS_TOKEN}`,
        }
      }
    );

    const backups = await response.json();

    if (backups.length === 0) {
      console.log('‚ùå Aucun backup disponible');
      return;
    }

    // 2. Prendre le dernier backup
    const latestBackup = backups[0];

    // 3. T√©l√©charger le backup (si backup quotidien, pas PITR)
    if (latestBackup.download_url) {
      const backupResponse = await fetch(latestBackup.download_url);
      const backupData = await backupResponse.text();

      // 4. Sauvegarder sur le NAS
      const timestamp = new Date().toISOString().replace(/:/g, '-').split('.')[0];
      const filename = `backup_${timestamp}.sql`;
      const filepath = path.join(BACKUP_DIR, filename);

      fs.writeFileSync(filepath, backupData);

      console.log(`‚úÖ Backup sauvegard√©: ${filepath}`);

      // 5. Nettoyer les vieux backups (garder 30 derniers)
      cleanOldBackups(BACKUP_DIR, 30);
    } else {
      console.log('‚ö†Ô∏è Backup PITR d√©tect√© - pas de t√©l√©chargement direct possible');
      console.log('Utilise plut√¥t pg_dump ou Supabase CLI');
    }

  } catch (error) {
    console.error('‚ùå Erreur lors du backup:', error);
  }
}

function cleanOldBackups(dir, keepCount) {
  const files = fs.readdirSync(dir)
    .filter(f => f.startsWith('backup_') && f.endsWith('.sql'))
    .map(f => ({
      name: f,
      time: fs.statSync(path.join(dir, f)).mtime.getTime()
    }))
    .sort((a, b) => b.time - a.time);

  // Supprimer les fichiers au-del√† de keepCount
  files.slice(keepCount).forEach(file => {
    fs.unlinkSync(path.join(dir, file.name));
    console.log(`üóëÔ∏è  Supprim√©: ${file.name}`);
  });
}

// Ex√©cuter le backup
createBackup();
```

### Automatiser avec Cron

```bash
# Toutes les heures
0 * * * * node /Users/jeremy/Desktop/claude/activelaser/scripts/backup-api.js

# Tous les jours √† 2h du matin
0 2 * * * node /Users/jeremy/Desktop/claude/activelaser/scripts/backup-api.js
```

---

## üî• SOLUTION 3: Vercel Cron Job (RECOMMAND√â)

### Cr√©er une API route dans ton projet

**Fichier: `src/app/api/cron/backup/route.ts`**

```typescript
import { createClient } from '@supabase/supabase-js';
import { NextResponse } from 'next/server';

// Protection: seul Vercel Cron peut appeler cette route
export async function GET(request: Request) {
  // V√©rifier que c'est bien Vercel Cron qui appelle
  const authHeader = request.headers.get('authorization');
  if (authHeader !== `Bearer ${process.env.CRON_SECRET}`) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  try {
    const supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_ROLE_KEY!
    );

    // 1. Exporter toutes les tables importantes
    const tables = [
      'contacts',
      'bookings',
      'orders',
      'payments',
      'email_logs',
      'branches',
      'products'
    ];

    const backupData: any = {
      timestamp: new Date().toISOString(),
      tables: {}
    };

    for (const table of tables) {
      const { data, error } = await supabase
        .from(table)
        .select('*');

      if (error) {
        console.error(`Erreur table ${table}:`, error);
        continue;
      }

      backupData.tables[table] = data;
    }

    // 2. Envoyer le backup quelque part (exemples ci-dessous)

    // Option A: Sauvegarder dans Supabase Storage
    const { error: uploadError } = await supabase
      .storage
      .from('backups')
      .upload(
        `backup_${Date.now()}.json`,
        JSON.stringify(backupData),
        { contentType: 'application/json' }
      );

    if (uploadError) {
      throw uploadError;
    }

    // Option B: Envoyer par email (avec Brevo)
    // const response = await fetch('https://api.brevo.com/v3/smtp/email', {
    //   method: 'POST',
    //   headers: {
    //     'api-key': process.env.BREVO_API_KEY!,
    //     'content-type': 'application/json'
    //   },
    //   body: JSON.stringify({
    //     sender: { email: 'backup@activegames.co.il' },
    //     to: [{ email: 'ton-email@gmail.com' }],
    //     subject: `Backup ActiveLaser ${new Date().toLocaleDateString()}`,
    //     attachment: [{
    //       content: Buffer.from(JSON.stringify(backupData)).toString('base64'),
    //       name: `backup_${Date.now()}.json`
    //     }]
    //   })
    // });

    // Option C: Webhook vers ton NAS/serveur
    // await fetch('https://ton-nas.com/api/backup', {
    //   method: 'POST',
    //   headers: { 'Content-Type': 'application/json' },
    //   body: JSON.stringify(backupData)
    // });

    return NextResponse.json({
      success: true,
      message: 'Backup cr√©√© avec succ√®s',
      tablesCount: Object.keys(backupData.tables).length
    });

  } catch (error) {
    console.error('Erreur backup:', error);
    return NextResponse.json({
      error: 'Backup failed',
      details: error
    }, { status: 500 });
  }
}
```

### Configuration Vercel Cron

**Fichier: `vercel.json` (√† la racine du projet)**

```json
{
  "crons": [
    {
      "path": "/api/cron/backup",
      "schedule": "0 */6 * * *"
    }
  ]
}
```

**Fr√©quences possibles:**
```
"0 * * * *"      ‚Üí Toutes les heures
"0 */6 * * *"    ‚Üí Toutes les 6 heures
"0 2 * * *"      ‚Üí Tous les jours √† 2h
"0 */12 * * *"   ‚Üí Toutes les 12 heures
```

**Variables d'environnement Vercel:**
```bash
CRON_SECRET=ton-secret-ici-genere-un-mot-de-passe-fort
```

---

## üéØ QUELLE SOLUTION CHOISIR ?

### Pour toi, je recommande:

**SOLUTION 3 (Vercel Cron) + Supabase Storage**

‚úÖ **Avantages:**
- Gratuit (inclus dans Vercel)
- Automatique (aucune machine √† laisser allum√©e)
- Fiable (tourne dans le cloud)
- Backup stock√© sur Supabase Storage (s√©curis√©)
- Peut envoyer email de confirmation

**Configuration rapide:**

1. Cr√©er le bucket `backups` dans Supabase Storage
2. Ajouter le fichier `src/app/api/cron/backup/route.ts`
3. Modifier `vercel.json`
4. Push sur GitHub
5. Ajouter `CRON_SECRET` dans Vercel
6. ‚úÖ Done !

---

## üìä COMPARAISON

| Solution | Gratuit | Auto | Machine allum√©e | Complexit√© |
|----------|---------|------|-----------------|------------|
| Script Local | ‚úÖ | ‚úÖ | ‚ö†Ô∏è Oui | Facile |
| API Node.js | ‚úÖ | ‚úÖ | ‚ö†Ô∏è Oui | Moyen |
| **Vercel Cron** | ‚úÖ | ‚úÖ | ‚úÖ Non | Facile |

---

## üîê BACKUP STORAGE OPTIONS

### Option A: Supabase Storage
- Stock√© avec tes donn√©es
- Facile d'acc√®s via dashboard
- Gratuit jusqu'√† 100GB

### Option B: Email automatique
- Tu re√ßois le backup par email
- Limite: taille email (~25MB)
- Bon pour petites bases

### Option C: Ton NAS
- Besoin d'exposer une API sur ton NAS
- Plus complexe mais contr√¥le total
- Stockage illimit√©

---

**Tu veux que je t'aide √† mettre en place quelle solution ?**
